## Research Interests
I am currently a Research Engineer at [InstaDeep](https://www.instadeep.com), working on Multi-Agent Reinforcement Learning (MARL). My broader research interests include Deep Learning (specifically Pruning, Generalization and Neural Architecture Search) and Reinforcement Learning (specifically Policy Gradient methods and MARL).

## Papers
**[Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization](https://arxiv.org/abs/2102.01670)** - Feb 2021.
*Kale-ab Tessera, Sara Hooker, Benjamin Rosman*

Training sparse networks to converge to the same performance as dense neural architectures has proven to be elusive. Recent work suggests that initialization is the key. However, while this direction of research has had some success, focusing on initialization alone appears to be inadequate. In this paper, we take a broader view of training sparse networks and consider the role of regularization, optimization and architecture choices on sparse models. We propose a simple experimental framework, Same Capacity Sparse vs Dense Comparison (SC-SDC), that allows for fair comparison of sparse and dense networks. Furthermore, we propose a new measure of gradient flow, Effective Gradient Flow (EGF), that better correlates to performance in sparse networks. Using top-line metrics, SC-SDC and EGF, we show that default choices of optimizers, activation functions and regularizers used for dense networks can disadvantage sparse networks. Based upon these findings, we show that gradient flow in sparse networks can be improved by reconsidering aspects of the architecture design and the training regime. Our work suggests that initialization is only one piece of the puzzle and taking a wider view of tailoring optimization to sparse networks yields promising results.

## MSc Dissertation
- Title - On Sparsity in Deep Learning.
- Lab - [Robotics, Autonomous Intelligence and Learning lab](http://www.raillab.org/people). 
- Supervisor - Dr. Benjamin Rosman. 
- Dissertation - to be added. 

## Presentations
- Presented a Spotlight talk at the Deep Learning Indaba 2019 - [video](https://www.youtube.com/watch?v=r36FyLukrAg),[slides](https://www.kaleabtessera.com/indaba_2019_presentation.pdf).  
- Presented a poster at the Deep Learning Indaba 2019 - [poster](https://www.kaleabtessera.com/indaba_2019_poster.pdf).
- Presentation on Neural Architecture Search for the Robotics, Autonomous Intelligence and Learning lab - [slides](https://www.kaleabtessera.com/rail_2019_nas.pdf).
- Presented a poster at MLSS London, 2019.

## Committees
### Indaba Application and Selection Committee 2020
Part of the committee making decisions relating to improvements to the Deep Learning Indaba applications and selections process. 
### Black in AI Reviewer 2017,2018
Reviewed papers focused broadly on Machine Learning.


## Summer Schools
### NeurIPS 2019
I attending NeurIPS 2019 as part of an award given by Microsoft. I attending workshops in Reinforcement Learning, Information Theory and Deep Learning. 
### Deep Learning Indaba 2019
- I was the Front-End architect for the Applications system -  [Baobab](https://github.com/deep-learning-indaba/Baobab).
- I was selected as a tutor for the following advanced level practicals - [build your own TensorFlow](https://colab.research.google.com/drive/14GeXkFd5pQKKNIJ7BMswP0ihlYg5nIbS#forceEdit=true&offline=true&sandboxMode=true), [optimization for deep learning](https://colab.research.google.com/drive/1Dn6nqhbhFnwdNtTHtHMCe-KRXKOTyp_G#forceEdit=true&offline=true&sandboxMode=true), [convolutional networks](https://colab.research.google.com/drive/1GhO1DN8J1lmgIgV1zuKKMWd6m0SCUC5m#forceEdit=true&offline=true&sandboxMode=true) and [recurrent neural networks](https://colab.research.google.com/drive/18r3RipZvESHPE-XM1Y8w9iIsJ8JXPK8s#forceEdit=true&offline=true&sandboxMode=true).

### MLSS London 2019 
The Machine Learning Summer School (MLSS) is a 12-day event where participants take intensive courses on a variety of topics in machine learning, ranging from optimization and Bayesian inference to deep learning, reinforcement learning and Gaussian processes.
### Deep Learning Indaba 2017,2018. 
One week intensive Summer School covering state of the art techniques in Machine Learning and AI. 
